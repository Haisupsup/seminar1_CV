{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f5a3de",
   "metadata": {},
   "source": [
    "## 인코더-디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae76aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce8449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e616bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([[[1, 2, 3]]], dtype=np.float32)\n",
    "output_data = np.array([[[2, 3, 4]]], dtype=np.float32)\n",
    "\n",
    "# 입력 데이터 형상 변경\n",
    "input_data = input_data[:, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3bae201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 정의\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "encoder_lstm = LSTM(units = 16, return_state = True)\n",
    "_, encoder_h, encoder_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6253fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디코더 정의\n",
    "decoder_inputs = Input(shape=(None,1))\n",
    "decoder_lstm = LSTM(units = 16, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=1, activation = 'linear')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a68f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs = decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6321522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.9420\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9028\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8638\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8249\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7862\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.7476\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7092\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6709\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6327\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5946\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5567\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5188\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4811\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4434\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4059\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3684\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.3310\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2937\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2565\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2193\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1822\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1451\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.1080\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0710\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0340\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.9970\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9601\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9231\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8861\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8491\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8120\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7749\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7378\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7006\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.6634\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6260\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5886\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5511\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5135\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4758\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.4379\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3999\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.3618\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3235\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2851\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2465\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2077\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1687\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1295\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0901\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0505\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0107\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9706\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9303\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8897\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8488\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8076\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7662\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7245\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6824\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6400\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5973\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5543\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5108\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4671\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4229\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3784\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3334\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2881\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2424\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1962\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1496\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1025\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0551\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0071\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9587\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9098\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8604\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8105\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7602\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7093\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6579\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6060\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5536\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5007\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4472\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3932\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3387\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2836\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2280\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1719\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1152\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0579\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0002\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9418\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8830\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8235\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7636\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7031\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab8b179f88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "model.fit([input_data, input_data], output_data, batch_size = 1, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263ff03",
   "metadata": {},
   "source": [
    "## Word2Vec 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d959e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (5.1.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.2 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-win_amd64.whl (270 kB)\n",
      "     ---------------------------------------- 270.2/270.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from click->nltk) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from importlib-metadata->click->nltk) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from importlib-metadata->click->nltk) (3.11.0)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.12.25 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a39704b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "184e919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x1ab9ede24c8>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "801a9bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tnv59\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f529c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "     normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1cf2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb596623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38cb7658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "     --------------------------------------- 24.0/24.0 MB 43.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from gensim) (1.21.6)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "     ------------------------------------- 983.8/983.8 kB 31.4 MB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c22727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "367c16e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8343969583511353), ('guy', 0.803366482257843), ('lady', 0.7468178868293762), ('boy', 0.7433486580848694), ('girl', 0.7384998798370361), ('gentleman', 0.7176277041435242), ('soldier', 0.7077347636222839), ('kid', 0.6815178394317627), ('friend', 0.6570190191268921), ('poet', 0.6566721796989441)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1de9805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2789fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8343969583511353), ('guy', 0.803366482257843), ('lady', 0.7468178868293762), ('boy', 0.7433486580848694), ('girl', 0.7384998798370361), ('gentleman', 0.7176277041435242), ('soldier', 0.7077347636222839), ('kid', 0.6815178394317627), ('friend', 0.6570190191268921), ('poet', 0.6566721796989441)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b6ab8",
   "metadata": {},
   "source": [
    "## Glove 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abdab6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glove_python_binary\n",
      "  Downloading glove_python_binary-0.2.0-cp37-cp37m-win_amd64.whl (225 kB)\n",
      "     -------------------------------------- 225.8/225.8 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-win_amd64.whl (34.1 MB)\n",
      "     --------------------------------------- 34.1/34.1 MB 43.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\tnv59\\appdata\\local\\anaconda3\\envs\\my_open\\lib\\site-packages (from glove_python_binary) (1.21.6)\n",
      "Installing collected packages: scipy, glove_python_binary\n",
      "Successfully installed glove_python_binary-0.2.0 scipy-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install glove_python_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc094f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "corpus = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cffed3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 20 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    }
   ],
   "source": [
    "corpus.fit(result, window=5)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "\n",
    "# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20.\n",
    "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa5a6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9602903226405134), ('guy', 0.886511040965002), ('girl', 0.8601827685608269), ('young', 0.8368183895002479)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1502e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('girl', 0.9406638550554005), ('kid', 0.8461361809953235), ('man', 0.8351529055028157), ('woman', 0.8341594103767832)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd4080a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('harvard', 0.8894672345057508), ('mit', 0.8587181620366068), ('stanford', 0.840225345859485), ('cambridge', 0.8302451990883875)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"university\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f848128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clean', 0.8376948203313356), ('fresh', 0.8318064084404437), ('air', 0.825492904192858), ('food', 0.8181621596765289)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"water\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPEN",
   "language": "python",
   "name": "my_open"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
